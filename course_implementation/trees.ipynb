{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b3d60e9",
   "metadata": {},
   "source": [
    "## KD Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1388,
   "id": "718f26a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1389,
   "id": "bc33bf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/hanifemamgholizadeh/Desktop/patter_recognition/data/tree_classification_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1390,
   "id": "2729eab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.402839</td>\n",
       "      <td>0.179845</td>\n",
       "      <td>1.432424</td>\n",
       "      <td>0.774566</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.902995</td>\n",
       "      <td>-1.241501</td>\n",
       "      <td>1.956614</td>\n",
       "      <td>0.512447</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.023094</td>\n",
       "      <td>1.270126</td>\n",
       "      <td>0.782203</td>\n",
       "      <td>-0.785725</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.331077</td>\n",
       "      <td>-0.069590</td>\n",
       "      <td>-0.258279</td>\n",
       "      <td>-0.339054</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.377452</td>\n",
       "      <td>0.816699</td>\n",
       "      <td>-3.009166</td>\n",
       "      <td>-1.553258</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  target\n",
       "0  -3.402839   0.179845   1.432424   0.774566       1\n",
       "1  -1.902995  -1.241501   1.956614   0.512447       1\n",
       "2  -1.023094   1.270126   0.782203  -0.785725       0\n",
       "3  -0.331077  -0.069590  -0.258279  -0.339054       0\n",
       "4  -3.377452   0.816699  -3.009166  -1.553258       2"
      ]
     },
     "execution_count": 1390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1391,
   "id": "8a067c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 1391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data['target']\n",
    "X = data.drop(columns=['target'])\n",
    "len(y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1392,
   "id": "c12af9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode:\n",
    "    def __init__(self, left_child=None, right_child=None, parent=None, value=None, feature=None, leaf_list=None):\n",
    "        self.left_child = left_child\n",
    "        self.right_child = right_child\n",
    "        self.parent = parent\n",
    "        self.value = value\n",
    "        self.feature = feature\n",
    "        self.leaf_list = leaf_list if leaf_list is not None else []\n",
    "        self.is_right_child = False\n",
    "        self.is_left_child = False\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return self.left_child is None and self.right_child is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1393,
   "id": "dc7e08cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(x1, x2):\n",
    "    return np.linalg.norm(np.array(x1) - np.array(x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1394,
   "id": "5e708aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance_to_wall(x, node):\n",
    "    feature = node.feature\n",
    "    wall_value = node.value\n",
    "    return abs(x[feature] - wall_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1395,
   "id": "3a3d1780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_KD_tree(X, y, parent_node=None, direction=None):\n",
    "    if len(X) <= 4 or len(np.unique(y)) == 1:\n",
    "        # Create a leaf node\n",
    "        return TreeNode(parent=parent_node, leaf_list=list(zip(X.values, y.values)))\n",
    "\n",
    "    # Choose a random feature and split on its median\n",
    "    feature = np.random.choice(X.columns)\n",
    "    median_value = X[feature].median()\n",
    "\n",
    "    # Split the data\n",
    "    left_indices = X[X[feature] <= median_value].index\n",
    "    right_indices = X[X[feature] > median_value].index\n",
    "\n",
    "    # Create current node\n",
    "    node = TreeNode(parent=parent_node, value=median_value, feature=feature)\n",
    "\n",
    "    if direction == 'left':\n",
    "        node.is_left_child = True\n",
    "    elif direction == 'right':\n",
    "        node.is_right_child = True\n",
    "\n",
    "    # Recursive construction\n",
    "    node.left_child = create_KD_tree(X.loc[left_indices], y.loc[left_indices], parent_node=node, direction='left')\n",
    "    node.right_child = create_KD_tree(X.loc[right_indices], y.loc[right_indices], parent_node=node, direction='right')\n",
    "\n",
    "    return node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1396,
   "id": "5eea7373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_first_search(tree_node: TreeNode, x, knn_distance, knn=[]):\n",
    "    if tree_node is None:\n",
    "        return None\n",
    "    \n",
    "    if tree_node.is_leaf():\n",
    "        leaf_list = tree_node.get_leaf_list()\n",
    "        for item in leaf_list:\n",
    "            calculate_distances = [calculate_distance(x, item) for item in leaf_list]\n",
    "        sorted_indices = np.argsort(calculate_distances)\n",
    "        knn.append(sorted_indices)\n",
    "        return tree_node.get_leaf_list()\n",
    "    \n",
    "    feature = tree_node.get_feature()\n",
    "    value = tree_node.get_value()\n",
    "    \n",
    "    if calculate_distance_to_wall(x[feature], value) < knn_distance:\n",
    "        return depth_first_search(tree_node, x, knn_distance, knn)\n",
    "    else:\n",
    "        return depth_first_search(tree_node.parent, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1397,
   "id": "43abcf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_first_search(node, x, knn_distance, knn_list):\n",
    "    if node is None:\n",
    "        return\n",
    "\n",
    "    if node.is_leaf():\n",
    "        for point, label in node.leaf_list:\n",
    "            dist = calculate_distance(x, point)\n",
    "            knn_list.append((dist, label))\n",
    "        return\n",
    "\n",
    "    feature = node.feature\n",
    "    value = node.value\n",
    "\n",
    "    # Choose which subtree to go first\n",
    "    if x[feature] <= value:\n",
    "        depth_first_search(node.left_child, x, knn_distance, knn_list)\n",
    "        if calculate_distance_to_wall(x, node) < knn_distance:\n",
    "            depth_first_search(node.right_child, x, knn_distance, knn_list)\n",
    "    else:\n",
    "        depth_first_search(node.right_child, x, knn_distance, knn_list)\n",
    "        if calculate_distance_to_wall(x, node) < knn_distance:\n",
    "            depth_first_search(node.left_child, x, knn_distance, knn_list)\n",
    "\n",
    "# Query the KD Tre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1398,
   "id": "ffe92a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors: [(0.0, 1), (0.7395099856826924, 1), (0.7622639206298912, 1)]\n",
      "Test Point prediction: 1\n",
      "True Label: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n4/8zh_hhf525v6v_00z9234_0h0000gn/T/ipykernel_29213/1229450982.py:18: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  print(\"Test Point prediction:\", mode(np.array([preds[1] for preds in neighbors])).mode[0])\n"
     ]
    }
   ],
   "source": [
    "def query_KD_tree(tree, x, k=1):\n",
    "    knn_list = []\n",
    "\n",
    "    # Initial DFS to fill neighbors\n",
    "    depth_first_search(tree, x, knn_distance=np.inf, knn_list=knn_list)\n",
    "\n",
    "    # Sort and return top-k neighbors\n",
    "    knn_list.sort(key=lambda tup: tup[0])\n",
    "    return knn_list[:k]\n",
    "\n",
    "# Example usage\n",
    "kd_tree = create_KD_tree(X, y)\n",
    "\n",
    "# Test on one point\n",
    "test_point = X.iloc[10]\n",
    "neighbors = query_KD_tree(kd_tree, test_point, k=3)\n",
    "print(\"Nearest Neighbors:\", neighbors)\n",
    "print(\"Test Point prediction:\", mode(np.array([preds[1] for preds in neighbors])).mode[0])\n",
    "print(\"True Label:\", y.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1399,
   "id": "6b67bfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def evaluate_model(tree, X, y, k=3):\n",
    "    predictions = []\n",
    "    for i in range(len(X)):\n",
    "        neighbors = query_KD_tree(tree, X.iloc[i], k)\n",
    "        predicted_label = mode(np.array([preds[1] for preds in neighbors])).mode[0]\n",
    "        predictions.append(predicted_label)\n",
    "    \n",
    "    accuracy = accuracy_score(y, predictions)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1400,
   "id": "6b7057f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n4/8zh_hhf525v6v_00z9234_0h0000gn/T/ipykernel_29213/3337161936.py:6: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  predicted_label = mode(np.array([preds[1] for preds in neighbors])).mode[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.895"
      ]
     },
     "execution_count": 1400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(kd_tree, X, y, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15333523",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1401,
   "id": "525ca514",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dtree = pd.read_csv('/Users/hanifemamgholizadeh/Desktop/patter_recognition/data/decision_tree_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1402,
   "id": "aa6657cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>student</th>\n",
       "      <th>credit_rating</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>23392</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>45535</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>93603</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>67256</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>104135</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  income  student  credit_rating  label\n",
       "0   56   23392        1              1      0\n",
       "1   46   45535        1              1      0\n",
       "2   32   93603        0              1      0\n",
       "3   25   67256        0              1      0\n",
       "4   38  104135        1              0      1"
      ]
     },
     "execution_count": 1402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dtree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1403,
   "id": "7bccd05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_dtree = df_dtree.drop(columns=['label'])\n",
    "y_dtree = df_dtree['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dtree, y_dtree, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1404,
   "id": "53b023ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTreeNode:\n",
    "    def __init__(self, left_child=None, right_child=None, value=None, feature=None,\n",
    "                 leaf_list=False, included_sample_size=0, impurity=None, sample_list=[], predicted_class=None):\n",
    "        self.left_child = left_child\n",
    "        self.right_child = right_child\n",
    "        self.value = value\n",
    "        self.feature = feature\n",
    "        self.leaf_list = leaf_list\n",
    "        self.included_sample_size = included_sample_size\n",
    "        self.impurity = impurity\n",
    "        self.samples_list = sample_list\n",
    "        self.predicted_class = predicted_class  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1405,
   "id": "fca823cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns_type(X=X_train):\n",
    "    columns_types = dict()\n",
    "\n",
    "    for column in X.columns:\n",
    "        if X[column].dtype == 'object':\n",
    "            columns_types[column] = 'categorical'\n",
    "        else:\n",
    "            if len(X[column].unique()) >= 10:\n",
    "                columns_types[column] = 'numerical'\n",
    "            else:\n",
    "                columns_types[column] = 'categorical'\n",
    "    return columns_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1406,
   "id": "b0f96cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_types = columns_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1407,
   "id": "988b8c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(labels):\n",
    "    probs = labels.value_counts(normalize=True)\n",
    "    return -np.sum([p * np.log2(p) for p in probs if p > 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1408,
   "id": "0e41d470",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def decision_tree(X, y, parent_node=None, list_of_indices=None, threshold=0.01):\n",
    "\n",
    "    columns_types = columns_type(X)\n",
    "\n",
    "    # Use consistent positional indices\n",
    "    if list_of_indices is None:\n",
    "        list_of_indices = list(range(len(X)))\n",
    "\n",
    "    # Subset the labels\n",
    "    labels = y.iloc[list_of_indices]\n",
    "\n",
    "    # Stopping conditions: pure or low impurity\n",
    "    p_vals = labels.value_counts(normalize=True)\n",
    "    current_impurity = -np.sum([p * np.log2(p) for p in p_vals if p > 0])\n",
    "\n",
    "    if current_impurity <= threshold or len(set(labels)) == 1 or len(list_of_indices) <= 1:\n",
    "        return DTreeNode(\n",
    "            included_sample_size=len(list_of_indices),\n",
    "            sample_list=list_of_indices,\n",
    "            impurity=current_impurity,\n",
    "            predicted_class=labels.mode()[0]\n",
    "        )\n",
    "\n",
    "    # Create current node\n",
    "    current_node = DTreeNode(\n",
    "        included_sample_size=len(list_of_indices),\n",
    "        sample_list=list_of_indices,\n",
    "        impurity=current_impurity\n",
    "    )\n",
    "\n",
    "    min_impurity = float('inf')\n",
    "    feature_to_split = None\n",
    "    value_to_split = None\n",
    "    best_left_indices = None\n",
    "    best_right_indices = None\n",
    "\n",
    "    for column in X.columns:\n",
    "        column_type = columns_types[column]\n",
    "        data = X[column].iloc[list_of_indices]\n",
    "\n",
    "        if column_type == 'numerical':\n",
    "            sorted_indices = data.sort_values().index.tolist()\n",
    "\n",
    "            for i in range(1, len(sorted_indices)):\n",
    "                left_indices = sorted_indices[:i]\n",
    "                right_indices = sorted_indices[i:]\n",
    "\n",
    "                if not left_indices or not right_indices:\n",
    "                    continue\n",
    "\n",
    "                y_left = y.iloc[left_indices]\n",
    "                y_right = y.iloc[right_indices]\n",
    "\n",
    "                entropy_left = entropy(y_left)\n",
    "                entropy_right = entropy(y_right)\n",
    "\n",
    "                weighted_entropy = (\n",
    "                    len(left_indices) / len(list_of_indices) * entropy_left +\n",
    "                    len(right_indices) / len(list_of_indices) * entropy_right\n",
    "                )\n",
    "\n",
    "                if weighted_entropy < min_impurity:\n",
    "                    min_impurity = weighted_entropy\n",
    "                    feature_to_split = column\n",
    "                    value_to_split = (data.iloc[i - 1] + data.iloc[i]) / 2\n",
    "                    best_left_indices = left_indices\n",
    "                    best_right_indices = right_indices\n",
    "\n",
    "        else:  # categorical\n",
    "            unique_values = data.unique()\n",
    "            for val in unique_values:\n",
    "                left_indices = data[data == val].index.tolist()\n",
    "                right_indices = data[data != val].index.tolist()\n",
    "\n",
    "                if not left_indices or not right_indices:\n",
    "                    continue\n",
    "\n",
    "                y_left = y.iloc[left_indices]\n",
    "                y_right = y.iloc[right_indices]\n",
    "\n",
    "                entropy_left = entropy(y_left)\n",
    "                entropy_right = entropy(y_right)\n",
    "\n",
    "                weighted_entropy = (\n",
    "                    len(left_indices) / len(list_of_indices) * entropy_left +\n",
    "                    len(right_indices) / len(list_of_indices) * entropy_right\n",
    "                )\n",
    "\n",
    "                if weighted_entropy < min_impurity:\n",
    "                    min_impurity = weighted_entropy\n",
    "                    feature_to_split = column\n",
    "                    value_to_split = val\n",
    "                    best_left_indices = left_indices\n",
    "                    best_right_indices = right_indices\n",
    "\n",
    "    # Final safeguard: avoid invalid or redundant splits\n",
    "    if (\n",
    "        best_left_indices is None or best_right_indices is None or\n",
    "        set(best_left_indices) == set(list_of_indices) or\n",
    "        set(best_right_indices) == set(list_of_indices)\n",
    "    ):\n",
    "        current_node.predicted_class = labels.mode()[0]\n",
    "        return current_node\n",
    "\n",
    "    # Store best split\n",
    "    current_node.feature = feature_to_split\n",
    "    current_node.value = value_to_split\n",
    "\n",
    "    # Recursively split\n",
    "    current_node.left_child = decision_tree(X, y, current_node, best_left_indices, threshold)\n",
    "    current_node.right_child = decision_tree(X, y, current_node, best_right_indices, threshold)\n",
    "\n",
    "    return current_node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1409,
   "id": "282b2f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "\n",
    "tree = decision_tree(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1410,
   "id": "52510557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one(sample, node):\n",
    "    while node.left_child and node.right_child:\n",
    "        val = sample[node.feature]\n",
    "\n",
    "        if columns_types[node.feature] == 'numerical':\n",
    "            if val <= node.value:\n",
    "                node = node.left_child\n",
    "            else:\n",
    "                node = node.right_child\n",
    "        else:  # categorical\n",
    "            if val == node.value:\n",
    "                node = node.left_child\n",
    "            else:\n",
    "                node = node.right_child\n",
    "\n",
    "    return node.predicted_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1411,
   "id": "20b26f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_all(X_test, root_node):\n",
    "    return X_test.apply(lambda row: predict_one(row, root_node), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1412,
   "id": "337fe169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "# Assume your full tree has been built like this\n",
    "root = decision_tree(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = predict_all(X_test, root)\n",
    "\n",
    "# Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1413,
   "id": "829308bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "def visualize_tree(node, dot=None, parent_name=None, edge_label=None, node_id=[0]):\n",
    "    if dot is None:\n",
    "        dot = Digraph()\n",
    "        dot.attr('node', shape='box')\n",
    "\n",
    "    current_id = str(node_id[0])\n",
    "    node_id[0] += 1\n",
    "\n",
    "    if node.left_child is None and node.right_child is None:\n",
    "        # Leaf node\n",
    "        label = f'Leaf\\nSamples: {node.included_sample_size}\\nClass: {getattr(node, \"predicted_class\", \"?\")}'\n",
    "    else:\n",
    "        label = f'{node.feature} ≤ {node.value}' if columns_types[node.feature] == 'numerical' else f'{node.feature} = {node.value}'\n",
    "        label += f'\\nSamples: {node.included_sample_size}\\nImpurity: {round(node.impurity, 3)}'\n",
    "\n",
    "    dot.node(current_id, label)\n",
    "\n",
    "    if parent_name is not None:\n",
    "        dot.edge(parent_name, current_id, label=edge_label)\n",
    "\n",
    "    # Recurse for children\n",
    "    if node.left_child is not None:\n",
    "        visualize_tree(node.left_child, dot, current_id, 'True', node_id)\n",
    "    if node.right_child is not None:\n",
    "        visualize_tree(node.right_child, dot, current_id, 'False', node_id)\n",
    "\n",
    "    return dot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1414,
   "id": "b3421e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the decision tree (assuming you've already done this)\n",
    "# root = decision_tree(X_train, y_train)\n",
    "\n",
    "# # Visualize it\n",
    "# dot = visualize_tree(root)\n",
    "# dot.render(\"my_tree\", format=\"png\", cleanup=False)  # Saves as my_tree.png\n",
    "# dot.view()  # Opens the image in default viewer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3172726d",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957e5ce5",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1415,
   "id": "4ba5279c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_data = pd.read_csv('/Users/hanifemamgholizadeh/Desktop/patter_recognition/data/random_forest_synthetic_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1416,
   "id": "72017d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>score</th>\n",
       "      <th>owns_house</th>\n",
       "      <th>has_loan</th>\n",
       "      <th>is_married</th>\n",
       "      <th>category_1</th>\n",
       "      <th>category_2</th>\n",
       "      <th>category_3</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>51905</td>\n",
       "      <td>0.936648</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>X</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>31258</td>\n",
       "      <td>0.039186</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>X</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>79176</td>\n",
       "      <td>0.417946</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>Y</td>\n",
       "      <td>High</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>47699</td>\n",
       "      <td>0.967581</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>X</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>36395</td>\n",
       "      <td>0.547972</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>Y</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  income     score  owns_house  has_loan  is_married category_1  \\\n",
       "0   56   51905  0.936648           1         1           0          B   \n",
       "1   69   31258  0.039186           0         0           0          A   \n",
       "2   46   79176  0.417946           1         1           1          C   \n",
       "3   32   47699  0.967581           0         0           0          A   \n",
       "4   60   36395  0.547972           0         1           1          C   \n",
       "\n",
       "  category_2 category_3  target  \n",
       "0          X        Low       1  \n",
       "1          X        Low       1  \n",
       "2          Y       High       1  \n",
       "3          X        Low       0  \n",
       "4          Y        Low       1  "
      ]
     },
     "execution_count": 1416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1417,
   "id": "dd4d3823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 1417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1418,
   "id": "d93abda9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 1418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rf_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1419,
   "id": "fa340d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_rf = rf_data.drop(columns=['target'])\n",
    "y_rf = rf_data['target']\n",
    "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X_rf, y_rf, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1420,
   "id": "111f50af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagging(X, sample_size=len(X)):\n",
    "    return X.sample(n=sample_size, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1421,
   "id": "1030ddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def train_rf(X, n_trees=10):\n",
    "    trees = []\n",
    "    for i in range(n_trees):\n",
    "        \n",
    "        sample = bagging(X).reset_index(drop=True)\n",
    "        \n",
    "        # Exclude 'target' when sampling features\n",
    "        feature_columns = random.sample(\n",
    "            list(sample.columns.difference(['target'])), \n",
    "            k=int(np.sqrt(len(sample.columns) - 1))\n",
    "        )\n",
    "        \n",
    "        # Call decision tree with selected features\n",
    "        tree = decision_tree(sample[feature_columns], sample['target'])\n",
    "        trees.append(tree)\n",
    "        \n",
    "    return trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1422,
   "id": "164cadf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one(sample, node):\n",
    "    columns_types = columns_type(X_test_rf)\n",
    "    while node.left_child and node.right_child:\n",
    "        val = sample[node.feature]\n",
    "\n",
    "        if columns_types[node.feature] == 'numerical':\n",
    "            if val <= node.value:\n",
    "                node = node.left_child\n",
    "            else:\n",
    "                node = node.right_child\n",
    "        else:  # categorical\n",
    "            if val == node.value:\n",
    "                node = node.left_child\n",
    "            else:\n",
    "                node = node.right_child\n",
    "\n",
    "    return node.predicted_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1423,
   "id": "5cbbd03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rf(trees, X_test):\n",
    "    predictions = []\n",
    "    for row in X_test.iterrows():\n",
    "        \n",
    "        votes = []\n",
    "        for tree in trees:\n",
    "            pred = predict_one(row[1], tree)\n",
    "            votes.append(pred)\n",
    "        final_prediction = mode(votes, keepdims=False).mode\n",
    "        predictions.append(final_prediction)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1424,
   "id": "520dd0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = train_rf(pd.concat([X_train_rf, y_train_rf], axis=1), n_trees=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1425,
   "id": "9af9d599",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = test_rf(trees, X_test_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1426,
   "id": "c03a3051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.725\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy:\", accuracy_score(y_test_rf, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9952999",
   "metadata": {},
   "source": [
    "## Regression Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1427,
   "id": "ba7e4c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_data = pd.read_csv('/Users/hanifemamgholizadeh/Desktop/patter_recognition/data/synthetic_regression_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1428,
   "id": "b97d5be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.745401</td>\n",
       "      <td>0.157146</td>\n",
       "      <td>9.561862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.507143</td>\n",
       "      <td>3.182052</td>\n",
       "      <td>22.621832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.319939</td>\n",
       "      <td>1.571780</td>\n",
       "      <td>19.402403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.986585</td>\n",
       "      <td>2.542853</td>\n",
       "      <td>11.445345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.560186</td>\n",
       "      <td>4.537832</td>\n",
       "      <td>-0.663557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2     target\n",
       "0   3.745401   0.157146   9.561862\n",
       "1   9.507143   3.182052  22.621832\n",
       "2   7.319939   1.571780  19.402403\n",
       "3   5.986585   2.542853  11.445345\n",
       "4   1.560186   4.537832  -0.663557"
      ]
     },
     "execution_count": 1428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1429,
   "id": "881c6a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_reg = regression_data.drop(columns=['target'])\n",
    "y_reg = regression_data['target']\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_reg = X_train_reg.reset_index(drop=True)\n",
    "y_train_reg = y_train_reg.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1430,
   "id": "f962477d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impurity_regression(y):\n",
    "    if len(y) == 0:\n",
    "        return 0\n",
    "    mean_y = np.mean(y)\n",
    "    return np.sum((y - mean_y) ** 2) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1460,
   "id": "c40b40e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_decision_tree_GRBT(X, y, parent_node=None, list_of_indices=None, threshold=0.01, gbrt_active=False, current_depth=0):\n",
    "    if list_of_indices is None:\n",
    "        list_of_indices = list(range(len(X)))\n",
    "\n",
    "    labels = y.iloc[list_of_indices]\n",
    "\n",
    "    # Compute regression impurity (variance)\n",
    "    current_impurity = impurity_regression(labels)\n",
    "\n",
    "    import numpy as np\n",
    "    if gbrt_active:\n",
    "        if current_depth >= 5:  # Limit depth for GBRT\n",
    "            return DTreeNode(\n",
    "            included_sample_size=len(list_of_indices),\n",
    "            sample_list=list_of_indices,\n",
    "            impurity=current_impurity,\n",
    "            predicted_class=labels.mean()\n",
    "        )\n",
    "        current_depth += 1\n",
    "        \n",
    "    columns_types = columns_type(X)  # Assume this function returns 'numerical' or 'categorical' per column\n",
    "\n",
    "    \n",
    "    # Stop if node is pure or impurity is below threshold\n",
    "    if current_impurity < threshold or len(set(labels)) == 1:\n",
    "        current_node = DTreeNode(\n",
    "            included_sample_size=len(list_of_indices),\n",
    "            sample_list=list_of_indices,\n",
    "            impurity=current_impurity,\n",
    "            predicted_class=labels.mean()\n",
    "        )\n",
    "        return current_node\n",
    "\n",
    "    # Create current node\n",
    "    current_node = DTreeNode(\n",
    "        included_sample_size=len(list_of_indices),\n",
    "        sample_list=list_of_indices,\n",
    "        impurity=current_impurity\n",
    "    )\n",
    "\n",
    "    # Initialize split search\n",
    "    min_impurity = float('inf')\n",
    "    feature_to_split = None\n",
    "    value_to_split = None\n",
    "    best_left_indices = None\n",
    "    best_right_indices = None\n",
    "\n",
    "    for column in X.columns:\n",
    "        column_type = columns_types[column]\n",
    "        data = X[column].iloc[list_of_indices]\n",
    "\n",
    "        if column_type == 'numerical':\n",
    "            sorted_indices = data.sort_values().index.tolist()\n",
    "\n",
    "            for i in range(1, len(sorted_indices)):\n",
    "                left_indices = sorted_indices[:i]\n",
    "                right_indices = sorted_indices[i:]\n",
    "\n",
    "                if not left_indices or not right_indices:\n",
    "                    continue\n",
    "\n",
    "                y_left = y.iloc[left_indices]\n",
    "                y_right = y.iloc[right_indices]\n",
    "\n",
    "                impurity_left = impurity_regression(y_left)\n",
    "                impurity_right = impurity_regression(y_right)\n",
    "\n",
    "                weighted_impurity = (\n",
    "                    len(left_indices) / len(list_of_indices) * impurity_left +\n",
    "                    len(right_indices) / len(list_of_indices) * impurity_right\n",
    "                )\n",
    "\n",
    "                if weighted_impurity < min_impurity:\n",
    "                    min_impurity = weighted_impurity\n",
    "                    feature_to_split = column\n",
    "                    value_to_split = (data.iloc[i - 1] + data.iloc[i]) / 2\n",
    "                    best_left_indices = left_indices\n",
    "                    best_right_indices = right_indices\n",
    "\n",
    "        else:  # categorical\n",
    "            unique_values = data.unique()\n",
    "            for val in unique_values:\n",
    "                left_indices = data[data == val].index.tolist()\n",
    "                right_indices = data[data != val].index.tolist()\n",
    "\n",
    "                if not left_indices or not right_indices:\n",
    "                    continue\n",
    "\n",
    "                y_left = y.iloc[left_indices]\n",
    "                y_right = y.iloc[right_indices]\n",
    "\n",
    "                impurity_left = impurity_regression(y_left)\n",
    "                impurity_right = impurity_regression(y_right)\n",
    "\n",
    "                weighted_impurity = (\n",
    "                    len(left_indices) / len(list_of_indices) * impurity_left +\n",
    "                    len(right_indices) / len(list_of_indices) * impurity_right\n",
    "                )\n",
    "\n",
    "                if weighted_impurity < min_impurity:\n",
    "                    min_impurity = weighted_impurity\n",
    "                    feature_to_split = column\n",
    "                    value_to_split = val\n",
    "                    best_left_indices = left_indices\n",
    "                    best_right_indices = right_indices\n",
    "\n",
    "    # Final safeguard: avoid bad splits\n",
    "    if (\n",
    "        best_left_indices is None or best_right_indices is None or\n",
    "        set(best_left_indices) == set(list_of_indices) or\n",
    "        set(best_right_indices) == set(list_of_indices)\n",
    "    ):\n",
    "        current_node.predicted_class = labels.mean()\n",
    "        return current_node\n",
    "\n",
    "    # Store best split\n",
    "    current_node.feature = feature_to_split\n",
    "    current_node.value = value_to_split\n",
    "\n",
    "    # Recursively grow the tree\n",
    "    if gbrt_active:\n",
    "        current_node.left_child = regression_decision_tree_GRBT(X, y, current_node, best_left_indices, threshold, gbrt_active, current_depth)\n",
    "        current_node.right_child = regression_decision_tree_GRBT(X, y, current_node, best_right_indices, threshold, gbrt_active, current_depth)\n",
    "    else:\n",
    "        current_node.left_child = regression_decision_tree_GRBT(X, y, current_node, best_left_indices, threshold)\n",
    "        current_node.right_child = regression_decision_tree_GRBT(X, y, current_node, best_right_indices, threshold)\n",
    "\n",
    "    return current_node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b832fdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = regression_decision_tree_GRBT(X_train_reg, y_train_reg, gbrt_active=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1462,
   "id": "215a580f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_types = columns_type(X_train_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1463,
   "id": "42893ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(85576) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(85577) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(85578) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'my_tree.pdf'"
      ]
     },
     "execution_count": 1463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the decision tree (assuming you've already done this)\n",
    "root = tree\n",
    "# Visualize it\n",
    "dot = visualize_tree(root)\n",
    "dot.render(\"my_tree\", format=\"png\", cleanup=False)  # Saves as my_tree.png\n",
    "dot.view()  # Opens the image in default viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1464,
   "id": "98015ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one(x, node):\n",
    "        while node.left_child or node.right_child:\n",
    "            if node.feature is None:\n",
    "                break\n",
    "            val = x[node.feature]\n",
    "            if isinstance(val, str):\n",
    "                if val == node.value:\n",
    "                    node = node.left_child\n",
    "                else:\n",
    "                    node = node.right_child\n",
    "            else:\n",
    "                if val <= node.value:\n",
    "                    node = node.left_child\n",
    "                else:\n",
    "                    node = node.right_child\n",
    "        return node.predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1465,
   "id": "0da21afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_tree(tree, X):\n",
    "    return X.apply(lambda row: predict_one(row, tree), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1466,
   "id": "083c32fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 12.7297\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred = predict_with_tree(tree, X_test_reg)\n",
    "\n",
    "# Compute MSE\n",
    "mse = mean_squared_error(y_test_reg, y_pred)\n",
    "print(f\"Test MSE: {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84570f6",
   "metadata": {},
   "source": [
    "## Gradient Boosted Regression Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ab0ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GBRT(X, y, n_estimators=100, learning_rate=0.1, threshold=0.01):\n",
    "    H = []\n",
    "    F = pd.Series(np.full(len(y), y.mean()), index=y.index) \n",
    "    for _ in range(n_estimators):\n",
    "        \n",
    "        residuals = y - F  \n",
    "        tree = regression_decision_tree(X, residuals, threshold=threshold)\n",
    "        pred = X.apply(lambda row: predict_one(row, tree), axis=1)\n",
    "        F += learning_rate * pred\n",
    "        H.append(tree)\n",
    "\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1449,
   "id": "02110b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_GBRT(H, X, learning_rate):\n",
    "    preds = pd.Series(np.full(len(X), 0.0), index=X.index)\n",
    "    for item in H:\n",
    "        preds += learning_rate * X.apply(lambda row: predict_one(row, item), axis=1)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1454,
   "id": "a061ebf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = GBRT(X_train_reg, y_train_reg, n_estimators=50, learning_rate=0.1, threshold=0.01)\n",
    "preds = prediction_GBRT(H, X_test_reg, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1455,
   "id": "35554e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 94.3258\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Compute MSE\n",
    "mse = mean_squared_error(y_test_reg, preds)\n",
    "print(f\"Test MSE: {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed31ed91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
