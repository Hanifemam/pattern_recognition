{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b3d60e9",
   "metadata": {},
   "source": [
    "## KD Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "718f26a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc33bf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/hanifemamgholizadeh/Desktop/patter_recognition/data/tree_classification_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2729eab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.402839</td>\n",
       "      <td>0.179845</td>\n",
       "      <td>1.432424</td>\n",
       "      <td>0.774566</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.902995</td>\n",
       "      <td>-1.241501</td>\n",
       "      <td>1.956614</td>\n",
       "      <td>0.512447</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.023094</td>\n",
       "      <td>1.270126</td>\n",
       "      <td>0.782203</td>\n",
       "      <td>-0.785725</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.331077</td>\n",
       "      <td>-0.069590</td>\n",
       "      <td>-0.258279</td>\n",
       "      <td>-0.339054</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.377452</td>\n",
       "      <td>0.816699</td>\n",
       "      <td>-3.009166</td>\n",
       "      <td>-1.553258</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  target\n",
       "0  -3.402839   0.179845   1.432424   0.774566       1\n",
       "1  -1.902995  -1.241501   1.956614   0.512447       1\n",
       "2  -1.023094   1.270126   0.782203  -0.785725       0\n",
       "3  -0.331077  -0.069590  -0.258279  -0.339054       0\n",
       "4  -3.377452   0.816699  -3.009166  -1.553258       2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a067c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data['target']\n",
    "X = data.drop(columns=['target'])\n",
    "len(y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c12af9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode:\n",
    "    def __init__(self, left_child=None, right_child=None, parent=None, value=None, feature=None, leaf_list=None):\n",
    "        self.left_child = left_child\n",
    "        self.right_child = right_child\n",
    "        self.parent = parent\n",
    "        self.value = value\n",
    "        self.feature = feature\n",
    "        self.leaf_list = leaf_list if leaf_list is not None else []\n",
    "        self.is_right_child = False\n",
    "        self.is_left_child = False\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return self.left_child is None and self.right_child is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc7e08cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(x1, x2):\n",
    "    return np.linalg.norm(np.array(x1) - np.array(x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e708aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance_to_wall(x, node):\n",
    "    feature = node.feature\n",
    "    wall_value = node.value\n",
    "    return abs(x[feature] - wall_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a3d1780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_KD_tree(X, y, parent_node=None, direction=None):\n",
    "    if len(X) <= 4 or len(np.unique(y)) == 1:\n",
    "        # Create a leaf node\n",
    "        return TreeNode(parent=parent_node, leaf_list=list(zip(X.values, y.values)))\n",
    "\n",
    "    # Choose a random feature and split on its median\n",
    "    feature = np.random.choice(X.columns)\n",
    "    median_value = X[feature].median()\n",
    "\n",
    "    # Split the data\n",
    "    left_indices = X[X[feature] <= median_value].index\n",
    "    right_indices = X[X[feature] > median_value].index\n",
    "\n",
    "    # Create current node\n",
    "    node = TreeNode(parent=parent_node, value=median_value, feature=feature)\n",
    "\n",
    "    if direction == 'left':\n",
    "        node.is_left_child = True\n",
    "    elif direction == 'right':\n",
    "        node.is_right_child = True\n",
    "\n",
    "    # Recursive construction\n",
    "    node.left_child = create_KD_tree(X.loc[left_indices], y.loc[left_indices], parent_node=node, direction='left')\n",
    "    node.right_child = create_KD_tree(X.loc[right_indices], y.loc[right_indices], parent_node=node, direction='right')\n",
    "\n",
    "    return node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5eea7373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_first_search(tree_node: TreeNode, x, knn_distance, knn=[]):\n",
    "    if tree_node is None:\n",
    "        return None\n",
    "    \n",
    "    if tree_node.is_leaf():\n",
    "        leaf_list = tree_node.get_leaf_list()\n",
    "        for item in leaf_list:\n",
    "            calculate_distances = [calculate_distance(x, item) for item in leaf_list]\n",
    "        sorted_indices = np.argsort(calculate_distances)\n",
    "        knn.append(sorted_indices)\n",
    "        return tree_node.get_leaf_list()\n",
    "    \n",
    "    feature = tree_node.get_feature()\n",
    "    value = tree_node.get_value()\n",
    "    \n",
    "    if calculate_distance_to_wall(x[feature], value) < knn_distance:\n",
    "        return depth_first_search(tree_node, x, knn_distance, knn)\n",
    "    else:\n",
    "        return depth_first_search(tree_node.parent, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43abcf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_first_search(node, x, knn_distance, knn_list):\n",
    "    if node is None:\n",
    "        return\n",
    "\n",
    "    if node.is_leaf():\n",
    "        for point, label in node.leaf_list:\n",
    "            dist = calculate_distance(x, point)\n",
    "            knn_list.append((dist, label))\n",
    "        return\n",
    "\n",
    "    feature = node.feature\n",
    "    value = node.value\n",
    "\n",
    "    # Choose which subtree to go first\n",
    "    if x[feature] <= value:\n",
    "        depth_first_search(node.left_child, x, knn_distance, knn_list)\n",
    "        if calculate_distance_to_wall(x, node) < knn_distance:\n",
    "            depth_first_search(node.right_child, x, knn_distance, knn_list)\n",
    "    else:\n",
    "        depth_first_search(node.right_child, x, knn_distance, knn_list)\n",
    "        if calculate_distance_to_wall(x, node) < knn_distance:\n",
    "            depth_first_search(node.left_child, x, knn_distance, knn_list)\n",
    "\n",
    "# Query the KD Tre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ffe92a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors: [(0.0, 1), (0.7395099856826924, 1), (0.7622639206298912, 1)]\n",
      "Test Point prediction: 1\n",
      "True Label: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n4/8zh_hhf525v6v_00z9234_0h0000gn/T/ipykernel_29213/1229450982.py:18: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  print(\"Test Point prediction:\", mode(np.array([preds[1] for preds in neighbors])).mode[0])\n"
     ]
    }
   ],
   "source": [
    "def query_KD_tree(tree, x, k=1):\n",
    "    knn_list = []\n",
    "\n",
    "    # Initial DFS to fill neighbors\n",
    "    depth_first_search(tree, x, knn_distance=np.inf, knn_list=knn_list)\n",
    "\n",
    "    # Sort and return top-k neighbors\n",
    "    knn_list.sort(key=lambda tup: tup[0])\n",
    "    return knn_list[:k]\n",
    "\n",
    "# Example usage\n",
    "kd_tree = create_KD_tree(X, y)\n",
    "\n",
    "# Test on one point\n",
    "test_point = X.iloc[10]\n",
    "neighbors = query_KD_tree(kd_tree, test_point, k=3)\n",
    "print(\"Nearest Neighbors:\", neighbors)\n",
    "print(\"Test Point prediction:\", mode(np.array([preds[1] for preds in neighbors])).mode[0])\n",
    "print(\"True Label:\", y.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b67bfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def evaluate_model(tree, X, y, k=3):\n",
    "    predictions = []\n",
    "    for i in range(len(X)):\n",
    "        neighbors = query_KD_tree(tree, X.iloc[i], k)\n",
    "        predicted_label = mode(np.array([preds[1] for preds in neighbors])).mode[0]\n",
    "        predictions.append(predicted_label)\n",
    "    \n",
    "    accuracy = accuracy_score(y, predictions)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b7057f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n4/8zh_hhf525v6v_00z9234_0h0000gn/T/ipykernel_29213/3337161936.py:6: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  predicted_label = mode(np.array([preds[1] for preds in neighbors])).mode[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.895"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(kd_tree, X, y, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15333523",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "525ca514",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dtree = pd.read_csv('/Users/hanifemamgholizadeh/Desktop/patter_recognition/data/decision_tree_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa6657cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>student</th>\n",
       "      <th>credit_rating</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>23392</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>45535</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>93603</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>67256</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>104135</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  income  student  credit_rating  label\n",
       "0   56   23392        1              1      0\n",
       "1   46   45535        1              1      0\n",
       "2   32   93603        0              1      0\n",
       "3   25   67256        0              1      0\n",
       "4   38  104135        1              0      1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dtree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7bccd05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_dtree = df_dtree.drop(columns=['label'])\n",
    "y_dtree = df_dtree['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dtree, y_dtree, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "53b023ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTreeNode:\n",
    "    def __init__(self, left_child=None, right_child=None, value=None, feature=None, leaf_list=False, included_sample_size=0, impurity=None, sample_list=[]):\n",
    "        self.left_child = left_child\n",
    "        self.right_child = right_child\n",
    "        self.value = value\n",
    "        self.feature = feature\n",
    "        self.leaf_list = leaf_list\n",
    "        self.included_sample_size = included_sample_size\n",
    "        self.impurity = impurity\n",
    "        self.samples_list = sample_list\n",
    "        predicted_class = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fca823cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_types = dict()\n",
    "\n",
    "for column in X_train.columns:\n",
    "    if X_train[column].dtype == 'object':\n",
    "        columns_types[column] = 'categorical'\n",
    "    else:\n",
    "        if len(X_train[column].unique()) >= 10:\n",
    "            columns_types[column] = 'numerical'\n",
    "        else:\n",
    "            columns_types[column] = 'categorical'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e41d470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(X, y, parent_node=None, list_of_indices=None, threshold=0.01):\n",
    "    print(\"Decision tree started\")\n",
    "    if list_of_indices is None:\n",
    "        list_of_indices = X.index.tolist()\n",
    "\n",
    "    labels = y.loc[list_of_indices]\n",
    "    \n",
    "    p0 = (labels == 0).sum() / len(labels)\n",
    "    p1 = (labels == 1).sum() / len(labels)\n",
    "    \n",
    "    current_impurity = 0\n",
    "    for p in [p0, p1]:\n",
    "        if p > 0:\n",
    "            current_impurity -= p * np.log2(p)\n",
    "\n",
    "    # Stop if impurity is low enough (pure or almost pure node)\n",
    "    # if current_impurity <= threshold:\n",
    "    #     leaf_node = DTreeNode(\n",
    "    #         included_sample_size=len(list_of_indices),\n",
    "    #         sample_list=list_of_indices,\n",
    "    #         impurity=current_impurity\n",
    "    #     )\n",
    "    #     # Assign most common class in this node\n",
    "    #     leaf_node.predicted_class = labels.mode()[0]\n",
    "    #     return leaf_node\n",
    "\n",
    "    # Initialize root or inner node\n",
    "    if parent_node is None:\n",
    "        current_node = DTreeNode(\n",
    "            included_sample_size=len(list_of_indices),\n",
    "            sample_list=list_of_indices,\n",
    "            impurity=current_impurity\n",
    "        )\n",
    "    else:\n",
    "        current_node = DTreeNode(\n",
    "            included_sample_size=len(list_of_indices),\n",
    "            sample_list=list_of_indices,\n",
    "            impurity=current_impurity\n",
    "        )\n",
    "\n",
    "    min_impurity = float('inf')\n",
    "    feature_to_split = None\n",
    "    value_to_split = None\n",
    "    best_left_indices = None\n",
    "    best_right_indices = None\n",
    "\n",
    "    for column in X.columns:\n",
    "        column_type = columns_types[column]\n",
    "        data = X.loc[list_of_indices, column]\n",
    "\n",
    "        if column_type == 'numerical':\n",
    "            sorted_indices = data.sort_values().index.tolist()\n",
    "\n",
    "            for i in range(1, len(sorted_indices)):\n",
    "                left_indices = sorted_indices[:i]\n",
    "                right_indices = sorted_indices[i:]\n",
    "\n",
    "                if len(left_indices) == 0 or len(right_indices) == 0:\n",
    "                    continue\n",
    "\n",
    "                y_left = y.loc[left_indices]\n",
    "                y_right = y.loc[right_indices]\n",
    "\n",
    "                def entropy(labels):\n",
    "                    probs = labels.value_counts(normalize=True)\n",
    "                    return -np.sum([p * np.log2(p) for p in probs if p > 0])\n",
    "\n",
    "                entropy_left = entropy(y_left)\n",
    "                entropy_right = entropy(y_right)\n",
    "\n",
    "                weighted_entropy = (len(left_indices) / len(list_of_indices)) * entropy_left + \\\n",
    "                                   (len(right_indices) / len(list_of_indices)) * entropy_right\n",
    "\n",
    "                if weighted_entropy < min_impurity:\n",
    "                    min_impurity = weighted_entropy\n",
    "                    feature_to_split = column\n",
    "                    value_to_split = (data.loc[sorted_indices[i - 1]] + data.loc[sorted_indices[i]]) / 2\n",
    "                    best_left_indices = left_indices\n",
    "                    best_right_indices = right_indices\n",
    "\n",
    "        else:  # categorical\n",
    "            unique_values = data.unique()\n",
    "            for val in unique_values:\n",
    "                left_indices = data[data == val].index.tolist()\n",
    "                right_indices = data[data != val].index.tolist()\n",
    "\n",
    "                if len(left_indices) == 0 or len(right_indices) == 0:\n",
    "                    continue\n",
    "\n",
    "                y_left = y.loc[left_indices]\n",
    "                y_right = y.loc[right_indices]\n",
    "\n",
    "                entropy_left = entropy(y_left)\n",
    "                entropy_right = entropy(y_right)\n",
    "\n",
    "                weighted_entropy = (len(left_indices) / len(list_of_indices)) * entropy_left + \\\n",
    "                                   (len(right_indices) / len(list_of_indices)) * entropy_right\n",
    "\n",
    "                if weighted_entropy < min_impurity:\n",
    "                    min_impurity = weighted_entropy\n",
    "                    feature_to_split = column\n",
    "                    value_to_split = val\n",
    "                    best_left_indices = left_indices\n",
    "                    best_right_indices = right_indices\n",
    "\n",
    "    # No split found (all features pure or constant)\n",
    "    if best_left_indices is None or best_right_indices is None:\n",
    "        current_node.predicted_class = labels.mode()[0]\n",
    "        return current_node\n",
    "\n",
    "    current_node.feature = feature_to_split\n",
    "    current_node.value = value_to_split\n",
    "\n",
    "    # Recursively grow the tree\n",
    "    current_node.left_child = decision_tree(X, y, parent_node=current_node, list_of_indices=best_left_indices, threshold=threshold)\n",
    "    current_node.right_child = decision_tree(X, y, parent_node=current_node, list_of_indices=best_right_indices, threshold=threshold)\n",
    "    print(f\"Node created with feature: {feature_to_split}, value: {value_to_split}, impurity: {current_impurity}\")\n",
    "    return current_node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "282b2f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.DTreeNode at 0x7fb64c643310>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree(X_train, y_train, parent_node=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "52510557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one(sample, node):\n",
    "    while node.left_child and node.right_child:\n",
    "        val = sample[node.feature]\n",
    "\n",
    "        if columns_types[node.feature] == 'numerical':\n",
    "            if val <= node.value:\n",
    "                node = node.left_child\n",
    "            else:\n",
    "                node = node.right_child\n",
    "        else:  # categorical\n",
    "            if val == node.value:\n",
    "                node = node.left_child\n",
    "            else:\n",
    "                node = node.right_child\n",
    "\n",
    "    return node.predicted_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "20b26f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_all(X_test, root_node):\n",
    "    return X_test.apply(lambda row: predict_one(row, root_node), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "337fe169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Assume your full tree has been built like this\n",
    "root = decision_tree(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = predict_all(X_test, root)\n",
    "\n",
    "# Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "829308bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "def visualize_tree(node, dot=None, parent_name=None, edge_label=None, node_id=[0]):\n",
    "    if dot is None:\n",
    "        dot = Digraph()\n",
    "        dot.attr('node', shape='box')\n",
    "\n",
    "    current_id = str(node_id[0])\n",
    "    node_id[0] += 1\n",
    "\n",
    "    if node.left_child is None and node.right_child is None:\n",
    "        # Leaf node\n",
    "        label = f'Leaf\\nSamples: {node.included_sample_size}\\nClass: {getattr(node, \"predicted_class\", \"?\")}'\n",
    "    else:\n",
    "        label = f'{node.feature} ≤ {node.value}' if columns_types[node.feature] == 'numerical' else f'{node.feature} = {node.value}'\n",
    "        label += f'\\nSamples: {node.included_sample_size}\\nImpurity: {round(node.impurity, 3)}'\n",
    "\n",
    "    dot.node(current_id, label)\n",
    "\n",
    "    if parent_name is not None:\n",
    "        dot.edge(parent_name, current_id, label=edge_label)\n",
    "\n",
    "    # Recurse for children\n",
    "    if node.left_child is not None:\n",
    "        visualize_tree(node.left_child, dot, current_id, 'True', node_id)\n",
    "    if node.right_child is not None:\n",
    "        visualize_tree(node.right_child, dot, current_id, 'False', node_id)\n",
    "\n",
    "    return dot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b3421e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my_tree.pdf'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the decision tree (assuming you've already done this)\n",
    "root = decision_tree(X_train, y_train)\n",
    "\n",
    "# Visualize it\n",
    "dot = visualize_tree(root)\n",
    "dot.render(\"my_tree\", format=\"png\", cleanup=False)  # Saves as my_tree.png\n",
    "dot.view()  # Opens the image in default viewer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3172726d",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957e5ce5",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4ba5279c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_data = pd.read_csv('/Users/hanifemamgholizadeh/Desktop/patter_recognition/data/random_forest_synthetic_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "72017d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>score</th>\n",
       "      <th>owns_house</th>\n",
       "      <th>has_loan</th>\n",
       "      <th>is_married</th>\n",
       "      <th>category_1</th>\n",
       "      <th>category_2</th>\n",
       "      <th>category_3</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>51905</td>\n",
       "      <td>0.936648</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>X</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>31258</td>\n",
       "      <td>0.039186</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>X</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>79176</td>\n",
       "      <td>0.417946</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>Y</td>\n",
       "      <td>High</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>47699</td>\n",
       "      <td>0.967581</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>X</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>36395</td>\n",
       "      <td>0.547972</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>Y</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  income     score  owns_house  has_loan  is_married category_1  \\\n",
       "0   56   51905  0.936648           1         1           0          B   \n",
       "1   69   31258  0.039186           0         0           0          A   \n",
       "2   46   79176  0.417946           1         1           1          C   \n",
       "3   32   47699  0.967581           0         0           0          A   \n",
       "4   60   36395  0.547972           0         1           1          C   \n",
       "\n",
       "  category_2 category_3  target  \n",
       "0          X        Low       1  \n",
       "1          X        Low       1  \n",
       "2          Y       High       1  \n",
       "3          X        Low       0  \n",
       "4          Y        Low       1  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dd4d3823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d93abda9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rf_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fa340d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_rf = rf_data.drop(columns=['target'])\n",
    "y_rf = rf_data['target']\n",
    "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X_rf, y_rf, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "111f50af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagging(X, sample_size=len(X)):\n",
    "    df = pd.DataFrame(columns=X.columns)\n",
    "    print(\"Bagging samples started\")\n",
    "    for _ in range(sample_size):\n",
    "        sample = X.sample(n=sample_size, replace=True)\n",
    "        df = pd.concat([df, sample], ignore_index=True)\n",
    "    print(\"Bagging samples completed\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1030ddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "def train_rf(X, n_trees=10):\n",
    "    trees = []\n",
    "    for _ in range(n_trees):\n",
    "        print(f\"Training tree {_ + 1}/{n_trees}\")\n",
    "        sample = bagging(X)\n",
    "        columns_sample = random.sample(list(sample.columns), k=int(np.sqrt(len(sample.columns))))\n",
    "        columns_sample.append('target')\n",
    "        tree = decision_tree(sample.drop(columns=columns_sample), sample['target'])\n",
    "        trees.append(tree)\n",
    "    return trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5cbbd03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rf(trees, X_test):\n",
    "    predictions = []\n",
    "    for i in range(len(X_test)):\n",
    "        votes = []\n",
    "        for tree in trees:\n",
    "            pred = predict_one(X_test.iloc[i], tree)\n",
    "            votes.append(pred)\n",
    "        final_prediction = mode(votes).mode[0]\n",
    "        predictions.append(final_prediction)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520dd0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tree 1/10\n",
      "Bagging samples started\n",
      "Bagging samples completed\n"
     ]
    }
   ],
   "source": [
    "trees = train_rf(pd.concat([X_train_rf, y_train_rf], axis=1), n_trees=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af9d599",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = test_rf(trees, X_test_rf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
